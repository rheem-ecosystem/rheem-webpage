+++
title = "BigDansing: A System for Big Data Cleansing"
show_title = "Paper at SIGMOD 2015"
conference = "SIGMOD"
year = "2015"
link = "http://www.sigmod2015.org/"
city = "Melbourne"
country =  "Australia"
type = ""
date = "2015-01-01T13:07:31+02:00"
author = "Zuhair Khayyat, Ihab F. Ilyas, Alekh Jindal, Samuel Madden, Mourad Ouzzani, Paolo Papotti, Jorge-Arnulfo QuianeÃÅ-Ruiz, Nan Tang and Si Yin"
imagen = "/img/screenshot/bigdansing.png"
paper = "/pdf/paper/bigdansing.pdf"
tags = ["publication"]
categories = ["publication"]
+++

Data cleansing approaches have usually focused on detecting and fixing errors with little attention to scaling to big datasets. This presents a serious impediment since data cleansing often involves costly computations such as enumerating pairs of tuples, handling inequality joins, and dealing with user-defined functions. In this paper, we present BigDansing, a Big Data Cleansing system to tackle efficiency, scalability, and ease-of-use issues in data cleansing. The system can run on top of most common general purpose data processing platforms, ranging from DBMSs to MapReduce-like frameworks. A user-friendly programming interface allows users to express data quality rules both declaratively and procedurally, with no requirement of being aware of the underlying distributed platform. BigDansing takes these rules into a series of transformations that enable distributed computations and several optimizations, such as shared scans and specialized joins operators. Experimental results on both synthetic and real datasets show that BigDansing outperforms existing baseline systems up to more than two orders of magnitude without sacrificing the quality provided by the repair algorithms.
